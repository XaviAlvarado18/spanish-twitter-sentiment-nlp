---
title: "ğŸ¦ Twitter Sentiment Analysis in Spanish Tweets"
subtitle: "Pipeline de AnÃ¡lisis de Sentimiento"
author: |
  - Kristopher Javier Alvarado LÃ³pez (CarnÃ©: 21188)  
  - Emilio Jose Solano Orozco (CarnÃ©: 21212)
format: 
  revealjs:
    theme: solarized
    transition: fade
    slide-number: true
execute:
  echo: true
  warning: false
  message: false
---

## ğŸ“‹ Objetivos

- Analizar tweets en espaÃ±ol.  
- Preprocesar texto con NLP (tokenizaciÃ³n, lematizaciÃ³n, limpieza).  
- Representar el texto con **BoW** y **TF-IDF**.  
- Aplicar modelos de Machine Learning para clasificaciÃ³n de sentimientos.  
- Evaluar y visualizar resultados.

## ğŸ“‚ 1. Carga de Datos

```{r}
library(readr)
df <- read_csv("data/sentiment_analysis_dataset.csv")
head(df)



```
## ğŸ› ï¸ 2. Preprocesamiento del Corpus

Pasos realizados:

1. EliminaciÃ³n de columna *sentiment*.  
2. NormalizaciÃ³n de texto (minÃºsculas, eliminaciÃ³n de sÃ­mbolos).  
3. TokenizaciÃ³n y stopwords en espaÃ±ol.  
4. LematizaciÃ³n con **stanza**.  

ğŸ’¡ AquÃ­ se aplicÃ³ tambiÃ©n similitud de Levenshtein para limpieza de palabras.


## âœï¸ 3. RepresentaciÃ³n del Texto

- Bolsa de Palabras (BoW)  
- TF-IDF  
- BETO embeddings (transformer en espaÃ±ol)

```{r}
library(tm)
library(SnowballC)

# Corpus en R
corpus <- Corpus(VectorSource(df$text))
tdm <- TermDocumentMatrix(corpus,
                         control = list(weighting = weightTfIdf))
inspect(tdm[1:10, 1:10])
```

## ğŸ” Resultados Visuales - BoW y TF-IDF con PCA


![](output_bow.png){width=70%}

En la representaciÃ³n con BoW (izquierda) los puntos quedan muy dispersos y no muestran una estructura clara â†’ la informaciÃ³n semÃ¡ntica es limitada. Con TF-IDF (derecha), se observa una mejor diferenciaciÃ³n, pero aÃºn los clusters se superponen mucho.


## ğŸ” Resultados Visuales - BETO embeddings con PCA

:::{.center}
![](output_beto.png){width=27%}
:::


Con BETO embeddings los datos presentan una distribuciÃ³n mÃ¡s compacta y con mayor coherencia semÃ¡ntica, reflejando mejor las relaciones entre tweets. Esto confirma que los modelos de lenguaje basados en transformers en espaÃ±ol (como BETO) superan a BoW/TF-IDF en tareas de anÃ¡lisis de sentimiento.

## ğŸ¤– 4. Modelo avanzado

Modelos probados en Python (integraciÃ³n con `reticulate`):

```{python, eval=FALSE}
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import classification_report

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
model = MultinomialNB()
model.fit(X_train, y_train)
y_pred = model.predict(X_test)
print(classification_report(y_test, y_pred))
```

<div style="display: flex; justify-content: center; gap: 20px;">

<img src="output_naive.png" width="45%">
<img src="output_svm.png" width="45%">

</div>


## ğŸ“Š 5. VisualizaciÃ³n de Resultados

```{r}
library(ggplot2)

ggplot(data.frame(f1=c(0.81, 0.76, 0.84),
                  model=c("Naive Bayes","SVM","LogReg")),
       aes(x=model, y=f1, fill=model)) +
  geom_col() +
  labs(title="ComparaciÃ³n de F1-Score por Modelo",
       y="F1-Score", x="Modelo")
```



---


## âœ… Conclusiones

- El preprocesamiento en espaÃ±ol es clave (stopwords + lematizaciÃ³n).  
- TF-IDF dio mejores resultados que BoW.  
- El modelo con mejor desempeÃ±o fue **SVM (hipotÃ©tico ejemplo)**.  
- El pipeline puede extenderse con embeddings (Word2Vec, BERT).



## ğŸ™Œ Gracias

Autores:  
- Kristopher Javier Alvarado LÃ³pez  
- Emilio Jose Solano Orozco  
